# ğŸŒŸ Awesome NAS

Welcome to **Awesome NAS** â€“ a curated collection of cutting-edge research papers, codebases, and experimental projects focused on **Neural Architecture Search (NAS)**. The goal is to explore, learn, and implement diverse NAS methodologies from the latest literature.

---

## ğŸ“„ Collected Research Papers (2024â€“2025)

| Year | Title | Paper | Code | Project Page | Notes |
|------|-------|-------|------|--------------|-------|
| 2024 | [Towards Accurate and Robust Architectures via Neural Architecture Search](https://arxiv.org/abs/2405.05502) | [PDF](https://arxiv.org/pdf/2405.05502.pdf) | â€“ | â€“ | ARNAS: multi-objective NAS for robustness |
| 2025 | [Efficient Global Neural Architecture Search](https://arxiv.org/abs/2502.03553) | [PDF](https://arxiv.org/pdf/2502.03553.pdf) | â€“ | â€“ | Macro-micro disjointed search |
| 2024 | [Design Principle Transfer in NAS via Large Language Models](https://arxiv.org/abs/2408.11330) | [PDF](https://arxiv.org/pdf/2408.11330.pdf) | â€“ | â€“ | LLM-guided architecture design |
| 2025 | [NAS using Attention Enhanced Precise Path Evaluation](https://www.nature.com/articles/s41598-025-94187-8) | [PDF](https://www.nature.com/articles/s41598-025-94187-8.pdf) | [GitHub](https://github.com/Zhangqian0616/AE-NAS) | â€“ | AE-NAS: attention for better path estimation |
| 2025 | [Multi-objective Differentiable NAS](https://openreview.net/forum?id=9mjZ800m7Y) | [PDF](https://openreview.net/pdf?id=9mjZ800m7Y) | â€“ | â€“ | Zero-shot, hardware-aware hypernetwork |
| 2024 | [NAS Finds Robust Models by Knowledge Distillation](https://proceedings.mlr.press/v244/nath24a.html) | [PDF](https://proceedings.mlr.press/v244/nath24a/nath24a.pdf) | [GitHub](https://github.com/Statistical-Deep-Learning/RNAS-CL) | â€“ | RNAS-CL: robustness through distillation |
| 2024 | [ViT NAS for Out-of-Distribution Generalization](https://papers.nips.cc/paper_files/paper/2024/hash/9952369f49ecc064d169fe6612cbf204-Abstract-Conference.html) | â€“ | â€“ | â€“ | OoD-ViT-NAS: benchmark for ViT search |
| 2024 | [NAS via Progressive Partial Connection with Attention](https://www.nature.com/articles/s41598-024-57236-2) | [PDF](https://www.nature.com/articles/s41598-024-57236-2.pdf) | â€“ | â€“ | PPCAtt-NAS: progressive + attention |
| 2025 | [Low-Rank Adapters Meet NAS for LLM Compression](https://arxiv.org/abs/2501.16372) | [PDF](https://arxiv.org/pdf/2501.16372.pdf) | â€“ | â€“ | Merges NAS with adapter tuning |
| 2024 | [Scalable RL-based NAS](https://arxiv.org/abs/2410.01431) | [PDF](https://arxiv.org/pdf/2410.01431.pdf) | â€“ | â€“ | Efficient RL-based search pipeline |

> âœ… Feel free to contribute by opening a PR or submitting an issue with your favorite NAS papers!

---

## ğŸ§  Categories of NAS

- ğŸ§® Gradient-based: DARTS, SNAS
- ğŸ§¬ Evolutionary: AmoebaNet, Large-scale Evolution
- ğŸ§‘â€ğŸ”¬ Reinforcement Learning-based: NASNet, ENAS
- ğŸ› ï¸ Hardware-Aware: ProxylessNAS, FBNet
- ğŸ’¨ Zero-cost & One-shot: TE-NAS, Zero-Cost Proxies, OFA

---

## ğŸ”¬ Ongoing Experiments

Check the [experiments](./experiments/) folder for code related to:
- NAS-Bench-101/201 analysis
- DARTS re-implementation
- Zero-cost proxy performance comparison

---

## ğŸ“¦ How to Use This Repo

1. Clone the repo  
   ```bash
   git clone https://github.com/yourusername/awesome-nas.git
   cd awesome-nas
